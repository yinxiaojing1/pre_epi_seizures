{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franciscosargo/.virtualenvs/pre_epi_seizures/local/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# State the parameters of the pipeline\n",
    "\n",
    "disk = '/mnt/pre_epi_seizures/'\n",
    "baseline_files = 'h5_files/processing_datasets/baseline_datasets_new'\n",
    "seizure_files = 'h5_files/processing_datasets/seizure_datasets_new'\n",
    "\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "from classification.load_for_class import *\n",
    "import convertpandas as cv_pd\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing as pp\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from interim_processing import *\n",
    "import iopes\n",
    "\n",
    "# Set parameters of analyssis\n",
    "feature_slot = 'hrv_time_features'\n",
    "\n",
    "# Chose hyper-parameters of acquisition (ix of saved files)\n",
    "hyper_param = 0\n",
    "\n",
    "\n",
    "patient_list = [5]\n",
    "lead_list = ['ECG-']\n",
    "scaler = pp.StandardScaler()\n",
    "rbf_feature = RBFSampler(gamma=1, random_state=1)\n",
    "interim_processing = [scaler]\n",
    "hist_bins = None\n",
    "dist = None\n",
    "flag_hist = True\n",
    "flag_andrews = True\n",
    "flag_series = True\n",
    "flag_box = True\n",
    "flag_pair = True\n",
    "assign_baseline = 'assign_equal_baseline_seizure'\n",
    "label_struct = {\n",
    "                        'inter_ictal':{\n",
    "                            'label': 'Inter-Ictal Data Points',\n",
    "                            'color': 'blue',\n",
    "                            'intervals_samples': [(1000 * 0 * 60, 1000 * 0 * 60 )]\n",
    "                                     },\n",
    "                        'pre_ictal':{\n",
    "                            'label': 'Pre-Ictal data points',\n",
    "                            'color': 'yellow',\n",
    "                            'intervals_samples': [(1000 * 20 * 60, 1000 * 49 * 60 )]\n",
    "                                     },\n",
    "                        'ictal':{\n",
    "                            'label': 'Ictal data points',\n",
    "                            'color': 'red',\n",
    "                            'intervals_samples': [(1000 * 50 * 60, 1000 * 55 * 60 )]\n",
    "                                 },\n",
    "                        }\n",
    "baseline_label_struct = {\n",
    "                         'baseline':{\n",
    "                            'label': 'Baseline Data Points',\n",
    "                            'color': 'green',\n",
    "                            'intervals_samples': [(0, 1000 * 120 * 60 )]\n",
    "                                    },\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('flag_box', True)('flag_series', True)('dist', None)('scaler', StandardScaler(copy=True, with_mean=True, with_std=True))('lead_list', ['ECG-'])('interim_processing', [StandardScaler(copy=True, with_mean=True, with_std=True)])('flag_hist', True)('assign_baseline', 'assign_equal_baseline_seizure')('label_struct', {'pre_ictal': {'color': 'yellow', 'intervals_samples': [(1200000, 2940000)], 'label': 'Pre-Ictal data points'}, 'inter_ictal': {'color': 'blue', 'intervals_samples': [(0, 0)], 'label': 'Inter-Ictal Data Points'}, 'ictal': {'color': 'red', 'intervals_samples': [(3000000, 3300000)], 'label': 'Ictal data points'}})('baseline_label_struct', {'baseline': {'color': 'green', 'intervals_samples': [(0, 7200000)], 'label': 'Baseline Data Points'}})('flag_andrews', True)('patient_list', [5])('hist_bins', None)\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "``/mnt/pre_epi_seizures/EDAnalysis`` does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-496b5f74f961>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                                     \u001b[0massign_baseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_baseline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                     \u001b[0mlabel_struct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_struct\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                                     baseline_label_struct = baseline_label_struct)\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meda_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meda_id\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/franciscosargo/pre_epi_seizures/pre_epi_seizures/iopes.pyc\u001b[0m in \u001b[0;36mget_eda_params_path\u001b[0;34m(disk, eda_dir, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m         table = pd.DataFrame([[params_str, new_id]],\n\u001b[1;32m     29\u001b[0m                              columns=['params', 'id'])  # Create new table\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_hdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/mdata'\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# save table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mfinal_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/franciscosargo/.virtualenvs/pre_epi_seizures/local/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mto_hdf\u001b[0;34m(self, path_or_buf, key, **kwargs)\u001b[0m\n\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpytables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpytables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_hdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_msgpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_or_buf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/franciscosargo/.virtualenvs/pre_epi_seizures/local/lib/python2.7/site-packages/pandas/io/pytables.pyc\u001b[0m in \u001b[0;36mto_hdf\u001b[0;34m(path_or_buf, key, value, mode, complevel, complib, append, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         with HDFStore(path_or_buf, mode=mode, complevel=complevel,\n\u001b[0;32m--> 279\u001b[0;31m                       complib=complib) as store:\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/franciscosargo/.virtualenvs/pre_epi_seizures/local/lib/python2.7/site-packages/pandas/io/pytables.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, mode, complevel, complib, fletcher32, **kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fletcher32\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfletcher32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/franciscosargo/.virtualenvs/pre_epi_seizures/local/lib/python2.7/site-packages/pandas/io/pytables.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIOError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'can not be written'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/franciscosargo/.virtualenvs/pre_epi_seizures/local/lib/python2.7/site-packages/tables/file.pyc\u001b[0m in \u001b[0;36mopen_file\u001b[0;34m(filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;31m# Finally, create the File instance, and return it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_uep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/franciscosargo/.virtualenvs/pre_epi_seizures/local/lib/python2.7/site-packages/tables/file.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m         \u001b[0;31m# Now, it is time to initialize the File extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0;31m# Check filters and set PyTables format version for new files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtables/hdf5extension.pyx\u001b[0m in \u001b[0;36mtables.hdf5extension.File._g_new (tables/hdf5extension.c:4577)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/franciscosargo/.virtualenvs/pre_epi_seizures/local/lib/python2.7/site-packages/tables/utils.pyc\u001b[0m in \u001b[0;36mcheck_file_access\u001b[0;34m(filename, mode)\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mcheck_file_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0mcheck_file_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mcheck_file_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/franciscosargo/.virtualenvs/pre_epi_seizures/local/lib/python2.7/site-packages/tables/utils.pyc\u001b[0m in \u001b[0;36mcheck_file_access\u001b[0;34m(filename, mode)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0mparentname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparentname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mF_OK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"``%s`` does not exist\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparentname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparentname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"``%s`` is not a directory\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparentname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: ``/mnt/pre_epi_seizures/EDAnalysis`` does not exist"
     ]
    }
   ],
   "source": [
    "eda_dir = 'EDAnalysis/'\n",
    "\n",
    "eda_id = iopes.get_eda_params_path(disk=disk,\n",
    "                                    eda_dir=eda_dir,\n",
    "                                    patient_list = patient_list,\n",
    "                                    lead_list = lead_list,\n",
    "                                    scaler = scaler,\n",
    "                                    interim_processing = interim_processing,\n",
    "                                    hist_bins = hist_bins,\n",
    "                                    dist = dist,\n",
    "                                    flag_hist = flag_hist,\n",
    "                                    flag_andrews = flag_andrews,\n",
    "                                    flag_series = flag_series,\n",
    "                                    flag_box = flag_box,\n",
    "                                    assign_baseline = assign_baseline,\n",
    "                                    label_struct = label_struct,\n",
    "                                    baseline_label_struct = baseline_label_struct)\n",
    "path = disk + eda_dir + eda_id + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Ingest Seizure Data\n",
    "path_to_load = disk + seizure_files + '.h5'\n",
    "path_to_map = disk + seizure_files + '_map.txt'\n",
    "\n",
    "# Feature group to analyse -- point of entry\n",
    "feature_name = get_feature_group_name_list(path_to_map,\n",
    "                                               feature_slot)[hyper_param]\n",
    "\n",
    "print feature_name\n",
    "\n",
    "\n",
    "seizure_data = cv_pd.convert_to_pandas(path_to_load, path_to_map,\n",
    "                        patient_list, feature_name,\n",
    "                        lead_list, label_struct)\n",
    "seizure_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Ingest Baseline Data\n",
    "\n",
    "# set Labeling structure\n",
    "path_to_load = disk + baseline_files + '.h5'\n",
    "path_to_map = disk + baseline_files + '_map.txt'\n",
    "\n",
    "# Feature group to analyse -- point of entry\n",
    "feature_name = get_feature_group_name_list(path_to_map,\n",
    "                                               feature_slot)[0]\n",
    "\n",
    "print feature_name\n",
    "\n",
    "baseline_data = cv_pd.convert_to_pandas(path_to_load, path_to_map,\n",
    "                        patient_list, feature_name,\n",
    "                        lead_list, baseline_label_struct)\n",
    "\n",
    "baseline_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Treat Baseline Data\n",
    "baseline_data = baseline_data.dropna(axis=0, how='any').reset_index(drop=True)\n",
    "\n",
    "baseline_data = globals()[assign_baseline](baseline_data,\n",
    "                                          seizure_data,\n",
    "                                         'seizure_nr',\n",
    "                                         'patient_nr')\n",
    "\n",
    "seizure_data = seizure_data.dropna(axis=0, how='any').reset_index(drop=True)\n",
    "\n",
    "data = pd.concat([seizure_data, baseline_data],\n",
    "                 ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Add Seizure Type\n",
    "cv_pd.add_seizure_types(data,\n",
    "                        'patient_nr',\n",
    "                        'seizure_nr',\n",
    "                        'types_of_seizure',\n",
    "                        'location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# state the Data metafeatures\n",
    "metafeatures = ['patient_nr', 'seizure_nr', 'time_sample', 'label', 'color', 'types_of_seizure', 'location']\n",
    "features = [column\n",
    "            for column in data.columns\n",
    "            if column not in metafeatures]\n",
    "\n",
    "# Drop missing values\n",
    "data = data.dropna(axis=0, how='any').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Interim process the data\n",
    "for step in interim_processing:\n",
    "    X = data[features]\n",
    "\n",
    "    X_norm_np = step.fit_transform(X)\n",
    "\n",
    "    #X_norm = pd.DataFrame(X_norm_np, columns=X.columns)\n",
    "\n",
    "    data[features] = X_norm_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modelation\n",
    "import sklearn.svm as svm\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.pipeline import *\n",
    "import sklearn.naive_bayes as nb\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.neural_network import *\n",
    "from sklearn.neighbors import *\n",
    "from keras.utils import np_utils\n",
    "from classification.keras_neural_nets import *\n",
    "\n",
    "# Group the data\n",
    "data_groups = data.groupby(['patient_nr',\n",
    "                            'seizure_nr',\n",
    "                            'types_of_seizure',\n",
    "                            'location'])\n",
    "group_id = 'seizure_nr'\n",
    "\n",
    "data_groups_list = list(data_groups)\n",
    "\n",
    "# prepare data for classification - watch out for memory concerns\n",
    "X = data[features]\n",
    "y = data['label']\n",
    "groups = data[group_id]\n",
    "\n",
    "\n",
    "# choose Pipeline **Details in pipelines.py \n",
    "#pipe = Pipeline([('SVC', svm.SVC())])\n",
    "#pipe = Pipeline([('GaussNB', nb.GaussianNB())])\n",
    "#pipe = Pipeline([('KNN', KNeighborsClassifier())]\n",
    "pipe = Pipeline( [('ANN', KerasClassifier(build_fn=dense_network,\n",
    "                                                input_dim = len(features),\n",
    "                                                output_dim = len(y.unique()),\n",
    "                                                verbose=0))])\n",
    "\n",
    "# choose parameter search method *coherent with Pipeline steps\n",
    "param_grid = [\n",
    "               {'estimator__C': [2**i for i in xrange(-5, 11)],\n",
    "                'estimator__gamma':[2**i for i in xrange(-15, 1)]},\n",
    "                  ]\n",
    "#param_grid = [\n",
    "#               {'GaussNB__priors': [None]},\n",
    "#                  ]\n",
    "\n",
    "param_grid = [\n",
    "              {'ANN__epochs': [2000],\n",
    "               'ANN__batch_size': [10**4],\n",
    "               'ANN__hidden_layers_nr': [i for i in xrange(1, 5)],\n",
    "               'ANN__hidden_nodes_per_layer': [2**i for i in xrange(1, 5)],\n",
    "               'ANN__hidden_nodes_activation': ['relu']\n",
    "              }\n",
    "                ]\n",
    "\n",
    "# define cross-validation strategy \n",
    "cv_out = LeavePGroupsOut(n_groups=1)\n",
    "cv_in = LeavePGroupsOut(n_groups=1)\n",
    "\n",
    "# choose scoring\n",
    "scoring = ['f1_macro', 'accuracy']\n",
    "\n",
    "# choose wether to perform new computation\n",
    "compute_all_new = True\n",
    "\n",
    "search_function = GridSearchCV\n",
    "\n",
    "hyper_param_heat = False\n",
    "# Get path to save the results\n",
    "#full_path = get_full_pipeline_name(path_to_save,\n",
    "#                                   file_to_save,\n",
    "#                                   pipe, \n",
    "#                                   scoring,\n",
    "#                                   param_grid,\n",
    "#                                   feature_names,\n",
    "#                                   cv_out,\n",
    "#                                   cv_in,\n",
    "#                                   trial)\n",
    "\n",
    "\n",
    "\n",
    "# plot_scatter(path_to_save, data_struct, class_metadata)\n",
    "\n",
    "# plot_full(file_to_save, data_struct, class_metadata)\n",
    "\n",
    "# Create directory to save results\n",
    "#make_dir(full_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_id = iopes.get_eda_params_path(disk=disk,\n",
    "                                   eda_dir=eda_dir + '/' + eda_id + '/' ,\n",
    "                                   pipe = str(pipe),\n",
    "                                   param_grid = param_grid,\n",
    "                                   cv_out = cv_out,\n",
    "                                   cv_in = cv_in,\n",
    "                                   scoring = scoring,\n",
    "                                   search_function = search_function,\n",
    "                                   group_id=group_id)\n",
    "\n",
    "path_to_save = disk + eda_dir + eda_id + '/' + clf_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_to_save = path\n",
    "\n",
    "\n",
    "import classification.eda.hist as plt_hist\n",
    "import classification.eda.andrews as plt_and\n",
    "import classification.eda.series as plt_ts\n",
    "import classification.eda.box as plt_box\n",
    "import classification.eda.scatter as plt_sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for data_patient_seizure in data_groups_list:\n",
    "\n",
    "    if flag_hist:\n",
    "        plt_hist.histogram(path_to_save,\n",
    "                                data_patient_seizure[1],\n",
    "                                data_patient_seizure[0],\n",
    "                                features,\n",
    "                                'time_sample',\n",
    "                                'patient_nr',\n",
    "                                'seizure_nr',\n",
    "                                'label',\n",
    "                                'color',\n",
    "                                 bins=hist_bins,\n",
    "                                 dist=dist)\n",
    "\n",
    "    \n",
    "    if flag_series:\n",
    "        plt_ts.time_series_plot(path_to_save, data_patient_seizure[1],\n",
    "                                features,\n",
    "                                'time_sample',\n",
    "                                'patient_nr',\n",
    "                                'seizure_nr',\n",
    "                                'label',\n",
    "                                'color')\n",
    "    if flag_andrews:\n",
    "        plt_and.andrews_curves(path_to_save,\n",
    "                                data_patient_seizure[1],\n",
    "                                data_patient_seizure[0],\n",
    "                                features,\n",
    "                                'time_sample',\n",
    "                                'patient_nr',\n",
    "                                'seizure_nr',\n",
    "                                'label',\n",
    "                                'color')\n",
    "    if flag_box:\n",
    "        plt_box.box_plot(path_to_save,\n",
    "                        data_patient_seizure[1],\n",
    "                        data_patient_seizure[0],\n",
    "                        features,\n",
    "                        'time_sample',\n",
    "                        'patient_nr',\n",
    "                        'seizure_nr',\n",
    "                        'label',\n",
    "                        'color')\n",
    "        \n",
    "    if flag_pair:\n",
    "\n",
    "        plt_sc.pair_plot(path_to_save,\n",
    "                        data_patient_seizure[1],\n",
    "                        data_patient_seizure[0],\n",
    "                        features,\n",
    "                        'time_sample',\n",
    "                        'patient_nr',\n",
    "                        'seizure_nr',\n",
    "                        'label',\n",
    "                        'color')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import classification.cross_validation as cv\n",
    "\n",
    "# ***********************************Learning****************************\n",
    "# Learn from data_struct using nested cross_validation\n",
    "# learninig is an optimization and respective test results\n",
    "# for each partition of the dataset according to cv_out\n",
    "learning_results = cv.nested_cross_validation(path_to_save,\n",
    "                                       X,y, groups,\n",
    "                                       pipe,\n",
    "                                       param_grid, scoring,\n",
    "                                       compute_all_new, cv_out, cv_in,\n",
    "                                       search_function)\n",
    "#************************************************************************\n",
    "groups = data_groups.groups.keys()\n",
    "\n",
    "for learning_result, group in zip(learning_results, groups):\n",
    "        learning_result['group'] = group\n",
    "        \n",
    "cv_object = learning_results\n",
    "\n",
    "cv.generate_classification_report(cv_object)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "if hyper_param_heat:\n",
    "    for clf, test in learning_results:\n",
    "        print clf.best_estimator_\n",
    "        cv_results = clf.cv_results_\n",
    "        keys = cv_results.keys()\n",
    "\n",
    "        for grid in param_grid:\n",
    "            estimator_params = [key \n",
    "                                for key in grid.keys()\n",
    "                                if 'estimator' in key]\n",
    "            print estimator_params\n",
    "            param_bi_comb = itertools.combinations(estimator_params, r=2)\n",
    "\n",
    "            for bi_comb in param_bi_comb:\n",
    "\n",
    "                for key in keys:\n",
    "\n",
    "                    if 'param' not in key and 'rank' not in key:\n",
    "                        metric = cv_results[key]\n",
    "                        df = metric.reshape(len([2**i for i in xrange(-5, 11)]), len([2**i for i in xrange(-15, 1)]))\n",
    "\n",
    "                        #df = pd.DataFrame(df, columns=[str(2**i) for i in xrange(-15, 1)])\n",
    "                        #df['ix'] = [str(2**i) for i in xrange(-5, 11)]\n",
    "                        #df.set_index('ix')\n",
    "\n",
    "                        plt.figure()\n",
    "                        sns.heatmap(df,\n",
    "                                    xticklabels=[2**i for i in xrange(-5, 11)],\n",
    "                                    yticklabels=[2**i for i in xrange(-15, 1)],\n",
    "                                    cbar_kws={'label': key},\n",
    "                                   )\n",
    "                        plt.title(key)\n",
    "                        plt.xlabel(bi_comb[0])\n",
    "                        plt.ylabel(bi_comb[1])\n",
    "                        #plt.savefig(path_to_save + '/' + key)\n",
    "                        plt.show()\n",
    "                        \n",
    "hyper_param_list=False                        \n",
    "if hyper_param_list:\n",
    "    for learning_result in learning_results:\n",
    "\n",
    "        cv_results = learning_result['cv_results']\n",
    "        keys = list(cv_results.keys())\n",
    "        print keys\n",
    "        \n",
    "        for grid in param_grid:\n",
    "            params = grid.keys()\n",
    "            print params\n",
    "            for param in params:\n",
    "                \n",
    "                key_param_variation = keys[keys.index('param_' + param)]\n",
    "                param_variation = cv_results[key_param_variation]\n",
    "                \n",
    "                print param_variation\n",
    "                stop\n",
    "                \n",
    "                \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from classification.cross_validation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report = generate_classification_report(cv_object)\n",
    "report.to_hdf(path_to_save + 'classification_resport.h5', '/report' )\n",
    "\n",
    "pd.read_hdf(path_to_save + 'classification_resport.h5', '/report' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "string = report.to_latex()\n",
    "print string.replace('\\_', \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "arrays = [['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'],['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']]\n",
    "tuples = list(zip(*arrays))\n",
    "index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])\n",
    "s = pd.DataFrame(np.random.randn(8, 4), index=arrays)\n",
    "s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print s.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
