{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franciscosargo/.virtualenvs/pre_epi_seizures/local/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# State the parameters of the pipeline\n",
    "\n",
    "disk = '/mnt/pre_epi_seizures/'\n",
    "baseline_files = 'h5_files/processing_datasets/baseline_datasets_new'\n",
    "seizure_files = 'h5_files/processing_datasets/seizure_datasets_new'\n",
    "\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "from classification.load_for_class import *\n",
    "import convertpandas as cv_pd\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing as pp\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from interim_processing import *\n",
    "import iopes\n",
    "\n",
    "# Set parameters of analyssis\n",
    "feature_slot = 'hrv_time_features'\n",
    "\n",
    "# Chose hyper-parameters of acquisition (ix of saved files)\n",
    "hyper_param = 0\n",
    "\n",
    "\n",
    "patient_list = [3]\n",
    "lead_list = ['ECG-']\n",
    "scaler = pp.StandardScaler()\n",
    "rbf_feature = RBFSampler(gamma=1, random_state=1)\n",
    "interim_processing = [scaler]\n",
    "hist_bins = None\n",
    "dist = None\n",
    "flag_hist = False\n",
    "flag_andrews = False\n",
    "flag_series = False\n",
    "flag_box = False\n",
    "flag_pair = False\n",
    "assign_baseline = 'assign_equal_baseline_seizure'\n",
    "label_struct = {\n",
    "                        'inter_ictal':{\n",
    "                            'label': 'Inter-Ictal Data Points',\n",
    "                            'color': 'blue',\n",
    "                            'intervals_samples': [(1000 * 0 * 60, 1000 * 0 * 60 )]\n",
    "                                     },\n",
    "                        'pre_ictal':{\n",
    "                            'label': 'Pre-Ictal data points',\n",
    "                            'color': 'yellow',\n",
    "                            'intervals_samples': [(1000 * 20 * 60, 1000 * 49 * 60 )]\n",
    "                                     },\n",
    "                        'ictal':{\n",
    "                            'label': 'Ictal data points',\n",
    "                            'color': 'red',\n",
    "                            'intervals_samples': [(1000 * 50 * 60, 1000 * 70 * 60 )]\n",
    "                                 },\n",
    "                        }\n",
    "baseline_label_struct = {\n",
    "                         'baseline':{\n",
    "                            'label': 'Baseline Data Points',\n",
    "                            'color': 'green',\n",
    "                            'intervals_samples': [(0, 1000 * 120 * 60 )]\n",
    "                                    },\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('flag_box', False)('flag_series', False)('dist', None)('scaler', StandardScaler(copy=True, with_mean=True, with_std=True))('lead_list', ['ECG-'])('interim_processing', [StandardScaler(copy=True, with_mean=True, with_std=True)])('flag_hist', False)('assign_baseline', 'assign_equal_baseline_seizure')('label_struct', {'pre_ictal': {'color': 'yellow', 'intervals_samples': [(1200000, 2940000)], 'label': 'Pre-Ictal data points'}, 'inter_ictal': {'color': 'blue', 'intervals_samples': [(0, 0)], 'label': 'Inter-Ictal Data Points'}, 'ictal': {'color': 'red', 'intervals_samples': [(3000000, 4200000)], 'label': 'Ictal data points'}})('baseline_label_struct', {'baseline': {'color': 'green', 'intervals_samples': [(0, 7200000)], 'label': 'Baseline Data Points'}})('flag_andrews', False)('patient_list', [3])('hist_bins', None)\n"
     ]
    }
   ],
   "source": [
    "eda_dir = 'EDAnalysis/'\n",
    "\n",
    "eda_id = iopes.get_eda_params_path(disk=disk,\n",
    "                              eda_dir=eda_dir,\n",
    "                        patient_list = patient_list,\n",
    "                          lead_list = lead_list,\n",
    "                            scaler = scaler,\n",
    "                            interim_processing = interim_processing,\n",
    "                            hist_bins = hist_bins,\n",
    "                            dist = dist,\n",
    "                            flag_hist = flag_hist,\n",
    "                            flag_andrews = flag_andrews,\n",
    "                            flag_series = flag_series,\n",
    "                            flag_box = flag_box,\n",
    "                            assign_baseline = assign_baseline,\n",
    "                            label_struct = label_struct,\n",
    "                            baseline_label_struct = baseline_label_struct)\n",
    "path = disk + eda_dir + eda_id + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-128b16bea608>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Feature group to analyse -- point of entry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m feature_name = get_feature_group_name_list(path_to_map,\n\u001b[0;32m----> 7\u001b[0;31m                                                feature_slot)[hyper_param]\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Ingest Seizure Data\n",
    "path_to_load = disk + seizure_files + '.h5'\n",
    "path_to_map = disk + seizure_files + '_map.txt'\n",
    "\n",
    "# Feature group to analyse -- point of entry\n",
    "feature_name = get_feature_group_name_list(path_to_map,\n",
    "                                               feature_slot)[hyper_param]\n",
    "\n",
    "print feature_name\n",
    "\n",
    "\n",
    "seizure_data = cv_pd.convert_to_pandas(path_to_load, path_to_map,\n",
    "                        patient_list, feature_name,\n",
    "                        lead_list, label_struct)\n",
    "seizure_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest Baseline Data\n",
    "\n",
    "# set Labeling structure\n",
    "path_to_load = disk + baseline_files + '.h5'\n",
    "path_to_map = disk + baseline_files + '_map.txt'\n",
    "\n",
    "\n",
    "\n",
    "# Feature group to analyse -- point of entry\n",
    "feature_name = get_feature_group_name_list(path_to_map,\n",
    "                                               feature_slot)[hyper_param]\n",
    "\n",
    "baseline_data = cv_pd.convert_to_pandas(path_to_load, path_to_map,\n",
    "                        patient_list, feature_name,\n",
    "                        lead_list, baseline_label_struct)\n",
    "\n",
    "baseline_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "baseline_data = baseline_data.dropna(axis=0, how='any').reset_index(drop=True)\n",
    "\n",
    "baseline_data = globals()[assign_baseline](baseline_data,\n",
    "                                          seizure_data,\n",
    "                                         'seizure_nr',\n",
    "                                         'patient_nr')\n",
    "#print 'Done'\n",
    "\n",
    "seizure_data = seizure_data.dropna(axis=0, how='any').reset_index(drop=True)\n",
    "\n",
    "data = pd.concat([seizure_data, baseline_data],\n",
    "                 ignore_index=True)\n",
    "\n",
    "#except Exception as e:\n",
    "#    print e\n",
    "#    data = seizure_data\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv_pd.add_seizure_types(data,\n",
    "                        'patient_nr',\n",
    "                        'seizure_nr',\n",
    "                        'types_of_seizure',\n",
    "                        'location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# state the Data metafeatures\n",
    "metafeatures = ['patient_nr', 'seizure_nr', 'time_sample', 'label', 'color', 'types_of_seizure', 'location']\n",
    "features = [column\n",
    "            for column in data.columns\n",
    "            if column not in metafeatures]\n",
    "\n",
    "# Drop missing values\n",
    "data = data.dropna(axis=0, how='any').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Interim process the data\n",
    "for step in interim_processing:\n",
    "    X = data[features]\n",
    "\n",
    "    X_norm_np = step.fit_transform(X)\n",
    "\n",
    "    #X_norm = pd.DataFrame(X_norm_np, columns=X.columns)\n",
    "\n",
    "    data[features] = X_norm_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP for Pima Indians Dataset with 10-fold cross validation via sklearn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy\n",
    " \n",
    "# Function to create model, required for KerasClassifier\n",
    "def dense_network(output_dim,\n",
    "                  input_dim,\n",
    "                  hidden_layers_nr,\n",
    "                  hidden_nodes_per_layer,\n",
    "                  hidden_nodes_activation):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Create Hidden Layer Topology\n",
    "    for layer in xrange(0, hidden_layers_nr):\n",
    "        model.add(Dense(hidden_nodes_per_layer,\n",
    "                        input_dim=input_dim,\n",
    "                        activation=hidden_nodes_activation))\n",
    " \n",
    "    # Add output layer\n",
    "    model.add(Dense(output_dim, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelation\n",
    "import sklearn.svm as svm\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.pipeline import *\n",
    "import sklearn.naive_bayes as nb\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.neural_network import *\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# Group the data\n",
    "data_groups = data.groupby(['patient_nr',\n",
    "                              'seizure_nr',\n",
    "                              'types_of_seizure',\n",
    "                              'location'])\n",
    "\n",
    "group_id = 'seizure_nr'\n",
    "\n",
    "data_groups_list = list(data_groups)\n",
    "\n",
    "# prepare data for classification - watch out for memory concerns\n",
    "X = data[features]\n",
    "y = data['label']\n",
    "groups = data[group_id]\n",
    "\n",
    "\n",
    "# choose Pipeline **Details in pipelines.py \n",
    "#pipe = Pipeline([('estimator', svm.SVC())])\n",
    "#pipe = Pipeline( [('GaussNB', nb.GaussianNB())])\n",
    "\n",
    "\n",
    "pipe = Pipeline( [('ANN', KerasClassifier(build_fn=dense_network,\n",
    "                                                input_dim = len(features),\n",
    "                                                output_dim = len(y.unique()),\n",
    "                                                verbose=0))])\n",
    "pipe_id = []\n",
    "#pipe = Pipeline([('estimator', MLPClassifier())])\n",
    "\n",
    "# choose parameter search method *coherent with Pipeline steps\n",
    "param_grid = [\n",
    "               {'estimator__C': [2**i for i in xrange(-5, 11)],\n",
    "                'estimator__gamma':[2**i for i in xrange(-15, 1)]},\n",
    "                  ]\n",
    "\n",
    "param_grid = [{'__activation': ['relu'],\n",
    "               'estimator__solver':['adam']}]\n",
    "\n",
    "\n",
    "#param_grid = [\n",
    "#               {'GaussNB__priors': [None]},\n",
    "#                  ]\n",
    "\n",
    "param_grid = [\n",
    "              {'ANN__epochs': [2000],\n",
    "               'ANN__batch_size': [10**4],\n",
    "               'ANN__hidden_layers_nr': [i for i in xrange(1, 5)],\n",
    "               'ANN__hidden_nodes_per_layer': [2**i for i in xrange(1, 5)],\n",
    "               'ANN__hidden_nodes_activation': ['relu']\n",
    "              }\n",
    "                ]\n",
    "\n",
    "# define cross-validation strategy \n",
    "cv_out = LeavePGroupsOut(n_groups=1)\n",
    "cv_in = LeavePGroupsOut(n_groups=1)\n",
    "\n",
    "# choose scoring\n",
    "scoring = ['f1_micro']\n",
    "\n",
    "# choose wether to perform new computation\n",
    "compute_all_new = True\n",
    "\n",
    "search_function = GridSearchCV\n",
    "\n",
    "hyper_param_heat = False\n",
    "# Get path to save the results\n",
    "#full_path = get_full_pipeline_name(path_to_save,\n",
    "#                                   file_to_save,\n",
    "#                                   pipe, \n",
    "#                                   scoring,\n",
    "#                                   param_grid,\n",
    "#                                   feature_names,\n",
    "#                                   cv_out,\n",
    "#                                   cv_in,\n",
    "#                                   trial)\n",
    "\n",
    "\n",
    "\n",
    "# plot_scatter(path_to_save, data_struct, class_metadata)\n",
    "\n",
    "# plot_full(file_to_save, data_struct, class_metadata)\n",
    "\n",
    "# Create directory to save results\n",
    "#make_dir(full_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_id = iopes.get_eda_params_path(disk=disk,\n",
    "                                   eda_dir=eda_dir + '/' + eda_id + '/' ,\n",
    "                                   pipe = str(pipe),\n",
    "                                   param_grid = param_grid,\n",
    "                                   cv_out = cv_out,\n",
    "                                   cv_in = cv_in,\n",
    "                                   scoring = scoring,\n",
    "                                   search_function = search_function,\n",
    "                                   group_id=group_id)\n",
    "\n",
    "path_to_save = disk + eda_dir + eda_id + '/' + clf_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_to_save = path\n",
    "\n",
    "\n",
    "import classification.eda.hist as plt_hist\n",
    "import classification.eda.andrews as plt_and\n",
    "import classification.eda.series as plt_ts\n",
    "import classification.eda.box as plt_box\n",
    "import classification.eda.scatter as plt_sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for data_patient_seizure in data_groups_list:\n",
    "\n",
    "    if flag_hist:\n",
    "        plt_hist.histogram(path_to_save,\n",
    "                                data_patient_seizure[1],\n",
    "                                data_patient_seizure[0],\n",
    "                                features,\n",
    "                                'time_sample',\n",
    "                                'patient_nr',\n",
    "                                'seizure_nr',\n",
    "                                'label',\n",
    "                                'color',\n",
    "                                 bins=hist_bins,\n",
    "                                 dist=dist)\n",
    "\n",
    "    \n",
    "    if flag_series:\n",
    "        plt_ts.time_series_plot(path_to_save, data_patient_seizure[1],\n",
    "                                features,\n",
    "                                'time_sample',\n",
    "                                'patient_nr',\n",
    "                                'seizure_nr',\n",
    "                                'label',\n",
    "                                'color')\n",
    "    if flag_andrews:\n",
    "        plt_and.andrews_curves(path_to_save,\n",
    "                                data_patient_seizure[1],\n",
    "                                data_patient_seizure[0],\n",
    "                                features,\n",
    "                                'time_sample',\n",
    "                                'patient_nr',\n",
    "                                'seizure_nr',\n",
    "                                'label',\n",
    "                                'color')\n",
    "    if flag_box:\n",
    "        plt_box.box_plot(path_to_save,\n",
    "                        data_patient_seizure[1],\n",
    "                        data_patient_seizure[0],\n",
    "                        features,\n",
    "                        'time_sample',\n",
    "                        'patient_nr',\n",
    "                        'seizure_nr',\n",
    "                        'label',\n",
    "                        'color')\n",
    "        \n",
    "    if flag_pair:\n",
    "\n",
    "        plt_sc.pair_plot(path_to_save,\n",
    "                        data_patient_seizure[1],\n",
    "                        data_patient_seizure[0],\n",
    "                        features,\n",
    "                        'time_sample',\n",
    "                        'patient_nr',\n",
    "                        'seizure_nr',\n",
    "                        'label',\n",
    "                        'color')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import classification.cross_validation as cv\n",
    "\n",
    "# ***********************************Learning****************************\n",
    "# Learn from data_struct using nested cross_validation\n",
    "# learninig is an optimization and respective test results\n",
    "# for each partition of the dataset according to cv_out\n",
    "learning_results = cv.nested_cross_validation(path_to_save,\n",
    "                                       X,y, groups,\n",
    "                                       pipe,\n",
    "                                       param_grid, scoring,\n",
    "                                       compute_all_new, cv_out, cv_in,\n",
    "                                       search_function)\n",
    "#************************************************************************\n",
    "groups = data_groups.groups.keys()\n",
    "\n",
    "for learning_result, group in zip(learning_results, groups):\n",
    "        learning_result['group'] = group\n",
    "        \n",
    "cv_object = learning_results\n",
    "cv_object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "if hyper_param_heat:\n",
    "    for clf, test in learning_results:\n",
    "        print clf.best_estimator_\n",
    "        cv_results = clf.cv_results_\n",
    "        keys = cv_results.keys()\n",
    "\n",
    "        for grid in param_grid:\n",
    "            estimator_params = [key \n",
    "                                for key in grid.keys()\n",
    "                                if 'estimator' in key]\n",
    "            print estimator_params\n",
    "            param_bi_comb = itertools.combinations(estimator_params, r=2)\n",
    "\n",
    "            for bi_comb in param_bi_comb:\n",
    "\n",
    "                for key in keys:\n",
    "\n",
    "                    if 'param' not in key and 'rank' not in key:\n",
    "                        metric = cv_results[key]\n",
    "                        df = metric.reshape(len([2**i for i in xrange(-5, 11)]), len([2**i for i in xrange(-15, 1)]))\n",
    "\n",
    "                        #df = pd.DataFrame(df, columns=[str(2**i) for i in xrange(-15, 1)])\n",
    "                        #df['ix'] = [str(2**i) for i in xrange(-5, 11)]\n",
    "                        #df.set_index('ix')\n",
    "\n",
    "                        plt.figure()\n",
    "                        sns.heatmap(df,\n",
    "                                    xticklabels=[2**i for i in xrange(-5, 11)],\n",
    "                                    yticklabels=[2**i for i in xrange(-15, 1)],\n",
    "                                    cbar_kws={'label': key},\n",
    "                                   )\n",
    "                        plt.title(key)\n",
    "                        plt.xlabel(bi_comb[0])\n",
    "                        plt.ylabel(bi_comb[1])\n",
    "                        #plt.savefig(path_to_save + '/' + key)\n",
    "                        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "def parse_classification_report(classification_report):\n",
    "    \"\"\"Parses sklearn classification report into a pandas dataframe.\"\"\"\n",
    "    return pd.read_fwf(StringIO(classification_report),lineterminator='\\n', index_col=0, colspecs=[(0,22),(22,32),(32,42),(42,52), (52, 62)]).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "\n",
    "def generate_classification_report(learning_results):\n",
    "    # report each test from each fold of the cross_validation scheme\n",
    "    report = pd.concat(map(_generate_classification_report, learning_results))\n",
    "     \n",
    "    # format\n",
    "    report = report.reset_index(level=0, drop=True)\n",
    "    return report\n",
    "\n",
    "def _generate_classification_report(learning_result):\n",
    "\n",
    "    # Get the parameters\n",
    "    best_estimator = learning_result['best_estimator']\n",
    "    best_params = learning_result['best_params']\n",
    "    \n",
    "    # Get the Test results\n",
    "    y_test = learning_result['y_test']\n",
    "    y_pred = learning_result['y_pred']\n",
    "    \n",
    "    # Get the test group\n",
    "    group = learning_result['group']\n",
    "\n",
    "    # Convert Test result to pandas daraframe\n",
    "    classification_report_df = parse_classification_report(classification_report(y_test, y_pred, digits=4))\n",
    "    classification_report_df['Labels'] = classification_report_df.index\n",
    "    classification_report_df = classification_report_df.reset_index(drop=True)\n",
    "    classification_report_df['Test Group'] = str(group)\n",
    "    classification_report_df['Model'] = str(best_estimator.named_steps.keys())\n",
    "    classification_report_df['Best Parameters'] = str(best_params)\n",
    "\n",
    "    # Set Collumns as indexes of the dataframe\n",
    "    classification_report_df.set_index(['Model',\n",
    "                                        'Best Parameters',\n",
    "                                        'Test Group',\n",
    "                                        'Labels'] , append=True, inplace=True)\n",
    "\n",
    "    return classification_report_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report = generate_classification_report(cv_object)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = report.to_latex()\n",
    "print string.replace('\\_', \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "arrays = [['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'],['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']]\n",
    "tuples = list(zip(*arrays))\n",
    "index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])\n",
    "s = pd.DataFrame(np.random.randn(8, 4), index=arrays)\n",
    "s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print s.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
