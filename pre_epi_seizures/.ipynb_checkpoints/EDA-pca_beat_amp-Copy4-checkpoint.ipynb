{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franciscosargo/.virtualenvs/pre_epi_seizures/local/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# State the parameters of the pipeline\n",
    "\n",
    "disk = '/mnt/pre_epi_seizures/'\n",
    "baseline_files = 'h5_files/processing_datasets/baseline_datasets_new'\n",
    "seizure_files = 'h5_files/processing_datasets/seizure_datasets_new'\n",
    "\n",
    "\n",
    "# Exploratory Data Analysis\n",
    "from classification.load_for_class import *\n",
    "import convertpandas as cv_pd\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing as pp\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from interim_processing import *\n",
    "import iopes\n",
    "\n",
    "# Set parameters of analyssis\n",
    "feature_slot = 'hrv_time_features'\n",
    "\n",
    "# Chose hyper-parameters of acquisition (ix of saved files)\n",
    "hyper_param = 0\n",
    "\n",
    "\n",
    "patient_list = [5]\n",
    "lead_list = ['ECG-']\n",
    "scaler = pp.StandardScaler()\n",
    "rbf_feature = RBFSampler(gamma=1, random_state=1)\n",
    "interim_processing = [scaler]\n",
    "hist_bins = None\n",
    "dist = None\n",
    "flag_hist = True\n",
    "flag_andrews = True\n",
    "flag_series = True\n",
    "flag_box = True\n",
    "flag_pair = True\n",
    "assign_baseline = 'assign_equal_baseline_seizure'\n",
    "label_struct = {\n",
    "                        'inter_ictal':{\n",
    "                            'label': 'Inter-Ictal Data Points',\n",
    "                            'color': 'blue',\n",
    "                            'intervals_samples': [(1000 * 0 * 60, 1000 * 0 * 60 )]\n",
    "                                     },\n",
    "                        'pre_ictal':{\n",
    "                            'label': 'Pre-Ictal data points',\n",
    "                            'color': 'yellow',\n",
    "                            'intervals_samples': [(1000 * 20 * 60, 1000 * 49 * 60 )]\n",
    "                                     },\n",
    "                        'ictal':{\n",
    "                            'label': 'Ictal data points',\n",
    "                            'color': 'red',\n",
    "                            'intervals_samples': [(1000 * 50 * 60, 1000 * 55 * 60 )]\n",
    "                                 },\n",
    "                        }\n",
    "baseline_label_struct = {\n",
    "                         'baseline':{\n",
    "                            'label': 'Baseline Data Points',\n",
    "                            'color': 'green',\n",
    "                            'intervals_samples': [(0, 1000 * 120 * 60 )]\n",
    "                                    },\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('flag_box', True)('flag_series', True)('dist', None)('scaler', StandardScaler(copy=True, with_mean=True, with_std=True))('lead_list', ['ECG-'])('interim_processing', [StandardScaler(copy=True, with_mean=True, with_std=True)])('flag_hist', True)('assign_baseline', 'assign_equal_baseline_seizure')('label_struct', {'pre_ictal': {'color': 'yellow', 'intervals_samples': [(1200000, 2940000)], 'label': 'Pre-Ictal data points'}, 'inter_ictal': {'color': 'blue', 'intervals_samples': [(0, 0)], 'label': 'Inter-Ictal Data Points'}, 'ictal': {'color': 'red', 'intervals_samples': [(3000000, 3300000)], 'label': 'Ictal data points'}})('baseline_label_struct', {'baseline': {'color': 'green', 'intervals_samples': [(0, 7200000)], 'label': 'Baseline Data Points'}})('flag_andrews', True)('patient_list', [13])('hist_bins', None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/franciscosargo/.virtualenvs/pre_epi_seizures/local/lib/python2.7/site-packages/pandas/core/generic.py:1299: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['params', 'id']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "eda_dir = 'EDAnalysis/'\n",
    "\n",
    "eda_id = iopes.get_eda_params_path(disk=disk,\n",
    "                                    eda_dir=eda_dir,\n",
    "                                    patient_list = patient_list,\n",
    "                                    lead_list = lead_list,\n",
    "                                    scaler = scaler,\n",
    "                                    interim_processing = interim_processing,\n",
    "                                    hist_bins = hist_bins,\n",
    "                                    dist = dist,\n",
    "                                    flag_hist = flag_hist,\n",
    "                                    flag_andrews = flag_andrews,\n",
    "                                    flag_series = flag_series,\n",
    "                                    flag_box = flag_box,\n",
    "                                    assign_baseline = assign_baseline,\n",
    "                                    label_struct = label_struct,\n",
    "                                    baseline_label_struct = baseline_label_struct)\n",
    "path = disk + eda_dir + eda_id + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/3000_1200/raw_$beginwin_samplerate:1000_win:0.001_init:0_finish:4200_endwin$__$beginparams_param:None_endparam$_/baseline_removal_$beginwin_win:0.001__init:0__finish:4200__samplerate:1000_endwin$__$beginparam_filt:MedianFIR_endparam$_/rpeak_detection_$beginwin_win:rpeaks__samplerate:1000_endwin$__$beginparam_method:hamilton_endparam$_/pca_beat_amp_computation_$beginwin_win:rpeaks__samplerate:1000_endwin$__$beginparam_nr_comp:5_endparam$_\n",
      "closed\n",
      "closed\n",
      "closed\n"
     ]
    }
   ],
   "source": [
    "# Ingest Seizure Data\n",
    "path_to_load = disk + seizure_files + '.h5'\n",
    "path_to_map = disk + seizure_files + '_map.txt'\n",
    "\n",
    "# Feature group to analyse -- point of entry\n",
    "feature_name = get_feature_group_name_list(path_to_map,\n",
    "                                               feature_slot)[hyper_param]\n",
    "\n",
    "print feature_name\n",
    "\n",
    "\n",
    "seizure_data = cv_pd.convert_to_pandas(path_to_load, path_to_map,\n",
    "                        patient_list, feature_name,\n",
    "                        lead_list, label_struct)\n",
    "seizure_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/raw_$beginwin_samplerate:1000_win:0.001_init:0_finish:7200_endwin$__$beginparams_param:None_endparam$_/baseline_removal_$beginwin_win:0.001__init:0__finish:4200__samplerate:1000_endwin$__$beginparam_filt:MedianFIR_endparam$_/rpeak_detection_$beginwin_win:rpeaks__samplerate:1000_endwin$__$beginparam_method:hamilton_endparam$_/pca_beat_amp_computation_$beginwin_win:rpeaks__samplerate:1000_endwin$__$beginparam_nr_comp:5_endparam$_\n",
      "closed\n",
      "closed\n",
      "closed\n"
     ]
    }
   ],
   "source": [
    "# Ingest Baseline Data\n",
    "\n",
    "# set Labeling structure\n",
    "path_to_load = disk + baseline_files + '.h5'\n",
    "path_to_map = disk + baseline_files + '_map.txt'\n",
    "\n",
    "# Feature group to analyse -- point of entry\n",
    "feature_name = get_feature_group_name_list(path_to_map,\n",
    "                                               feature_slot)[0]\n",
    "\n",
    "print feature_name\n",
    "\n",
    "baseline_data = cv_pd.convert_to_pandas(path_to_load, path_to_map,\n",
    "                        patient_list, feature_name,\n",
    "                        lead_list, baseline_label_struct)\n",
    "\n",
    "baseline_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'dropna'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-90747a8fea18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Treat Baseline Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbaseline_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseline_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'any'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m baseline_data = globals()[assign_baseline](baseline_data,\n\u001b[1;32m      5\u001b[0m                                           \u001b[0mseizure_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'dropna'"
     ]
    }
   ],
   "source": [
    "# Treat Baseline Data\n",
    "baseline_data = baseline_data.dropna(axis=0, how='any').reset_index(drop=True)\n",
    "\n",
    "baseline_data = globals()[assign_baseline](baseline_data,\n",
    "                                          seizure_data,\n",
    "                                         'seizure_nr',\n",
    "                                         'patient_nr')\n",
    "\n",
    "seizure_data = seizure_data.dropna(axis=0, how='any').reset_index(drop=True)\n",
    "\n",
    "data = pd.concat([seizure_data, baseline_data],\n",
    "                 ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add Seizure Type\n",
    "cv_pd.add_seizure_types(data,\n",
    "                        'patient_nr',\n",
    "                        'seizure_nr',\n",
    "                        'types_of_seizure',\n",
    "                        'location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# state the Data metafeatures\n",
    "metafeatures = ['patient_nr', 'seizure_nr', 'time_sample', 'label', 'color', 'types_of_seizure', 'location']\n",
    "features = [column\n",
    "            for column in data.columns\n",
    "            if column not in metafeatures]\n",
    "\n",
    "# Drop missing values\n",
    "data = data.dropna(axis=0, how='any').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Interim process the data\n",
    "for step in interim_processing:\n",
    "    X = data[features]\n",
    "\n",
    "    X_norm_np = step.fit_transform(X)\n",
    "\n",
    "    #X_norm = pd.DataFrame(X_norm_np, columns=X.columns)\n",
    "\n",
    "    data[features] = X_norm_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelation\n",
    "import sklearn.svm as svm\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.pipeline import *\n",
    "import sklearn.naive_bayes as nb\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.neural_network import *\n",
    "from sklearn.neighbors import *\n",
    "from keras.utils import np_utils\n",
    "from classification.keras_neural_nets import *\n",
    "\n",
    "# Group the data\n",
    "data_groups = data.groupby(['patient_nr',\n",
    "                            'seizure_nr',\n",
    "                            'types_of_seizure',\n",
    "                            'location'])\n",
    "group_id = 'seizure_nr'\n",
    "\n",
    "label = 'label'\n",
    "\n",
    "data_groups_list = list(data_groups)\n",
    "\n",
    "\n",
    "\n",
    "# choose Pipeline **Details in pipelines.py \n",
    "pipe = Pipeline([('SVC', svm.SVC())])\n",
    "#pipe = Pipeline([('GaussNB', nb.GaussianNB())])\n",
    "#pipe = Pipeline([('KNN', KNeighborsClassifier())])\n",
    "#pipe = Pipeline( [('ANN', KerasClassifier(build_fn=dense_network,\n",
    " #                                               input_dim = len(features),\n",
    " #                                               output_dim = len(y.unique()),\n",
    "#                                                verbose=0))])\n",
    "\n",
    "# choose parameter search method *coherent with Pipeline steps\n",
    "param_grid = [\n",
    "               {'SVC__C': [2**i for i in xrange(-5, 11)],\n",
    "                'SVC__gamma':[2**i for i in xrange(-15, 1)]},\n",
    "                 ]\n",
    "#param_grid = [\n",
    "               #{'GaussNB__priors': [None]},\n",
    "                 # ]\n",
    "#param_grid = [\n",
    "#               {'KNN__n_neighbors': [n + 1 \n",
    " #                                     for n in xrange(0, 16, 2)]},\n",
    " #                 ]\n",
    "\n",
    "\n",
    "# define cross-validation strategy \n",
    "cv_out = LeavePGroupsOut(n_groups=1)\n",
    "cv_in = LeavePGroupsOut(n_groups=1)\n",
    "\n",
    "# choose scoring\n",
    "scoring = ['f1_macro', 'accuracy']\n",
    "\n",
    "# choose wether to perform new computation\n",
    "compute_all_new = True\n",
    "plot_eda_all_new = True\n",
    "\n",
    "search_function = GridSearchCV\n",
    "\n",
    "hyper_param_heat = False\n",
    "# Get path to save the results\n",
    "#full_path = get_full_pipeline_name(path_to_save,\n",
    "#                                   file_to_save,\n",
    "#                                   pipe, \n",
    "#                                   scoring,\n",
    "#                                   param_grid,\n",
    "#                                   feature_names,\n",
    "#                                   cv_out,\n",
    "#                                   cv_in,\n",
    "#                                   trial)\n",
    "\n",
    "\n",
    "\n",
    "# plot_scatter(path_to_save, data_struct, class_metadata)\n",
    "\n",
    "# plot_full(file_to_save, data_struct, class_metadata)\n",
    "\n",
    "# Create directory to save results\n",
    "#make_dir(full_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_id = iopes.get_eda_params_path(disk=disk,\n",
    "                                   eda_dir=eda_dir + '/' + eda_id + '/' ,\n",
    "                                   pipe = str(pipe),\n",
    "                                   param_grid = param_grid,\n",
    "                                   cv_out = cv_out,\n",
    "                                   cv_in = cv_in,\n",
    "                                   scoring = scoring,\n",
    "                                   search_function = search_function,\n",
    "                                   group_id=group_id,\n",
    "                                   label=label)\n",
    "\n",
    "path_to_save = disk + eda_dir + eda_id + '/' + clf_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import classification.eda.hist as plt_hist\n",
    "import classification.eda.andrews as plt_and\n",
    "import classification.eda.series as plt_ts\n",
    "import classification.eda.box as plt_box\n",
    "import classification.eda.scatter as plt_sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "    \n",
    "if plot_eda_all_new:\n",
    "\n",
    "    for data_patient_seizure in data_groups_list:\n",
    "\n",
    "        if flag_hist:\n",
    "            plt_hist.histogram(path_to_save,\n",
    "                                    data_patient_seizure[1],\n",
    "                                    data_patient_seizure[0],\n",
    "                                    features,\n",
    "                                    'time_sample',\n",
    "                                    'patient_nr',\n",
    "                                    'seizure_nr',\n",
    "                                    'label',\n",
    "                                    'color',\n",
    "                                     bins=hist_bins,\n",
    "                                     dist=dist)\n",
    "\n",
    "\n",
    "        if flag_series:\n",
    "            plt_ts.time_series_plot(path_to_save, data_patient_seizure[1],\n",
    "                                    features,\n",
    "                                    'time_sample',\n",
    "                                    'patient_nr',\n",
    "                                    'seizure_nr',\n",
    "                                    'label',\n",
    "                                    'color')\n",
    "        if flag_andrews:\n",
    "            plt_and.andrews_curves(path_to_save,\n",
    "                                    data_patient_seizure[1],\n",
    "                                    data_patient_seizure[0],\n",
    "                                    features,\n",
    "                                    'time_sample',\n",
    "                                    'patient_nr',\n",
    "                                    'seizure_nr',\n",
    "                                    'label',\n",
    "                                    'color')\n",
    "        if flag_box:\n",
    "            plt_box.box_plot(path_to_save,\n",
    "                            data_patient_seizure[1],\n",
    "                            data_patient_seizure[0],\n",
    "                            features,\n",
    "                            'time_sample',\n",
    "                            'patient_nr',\n",
    "                            'seizure_nr',\n",
    "                            'label',\n",
    "                            'color')\n",
    "\n",
    "        if flag_pair:\n",
    "\n",
    "            plt_sc.pair_plot(path_to_save,\n",
    "                            data_patient_seizure[1],\n",
    "                            data_patient_seizure[0],\n",
    "                            features,\n",
    "                            'time_sample',\n",
    "                            'patient_nr',\n",
    "                            'seizure_nr',\n",
    "                            'label',\n",
    "                            'color')\n",
    "            \n",
    "else:\n",
    "    import os\n",
    "    from IPython.display import Image\n",
    "    a = [name for name in os.listdir(path_to_save) if name.endswith(\".png\")]\n",
    "    for image in a:\n",
    "        display(Image(filename=path_to_save + image))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import classification.cross_validation as cv\n",
    "\n",
    "# ***********************************Learning****************************\n",
    "# Learn from data_struct using nested cross_validation\n",
    "# learninig is an optimization and respective test results\n",
    "# for each partition of the dataset according to cv_out\n",
    "\n",
    "\n",
    "# prepare data for classification - watch out for memory concerns\n",
    "X = data[features]\n",
    "y = data[label]\n",
    "groups = data[group_id]\n",
    "\n",
    "learning_results = cv.nested_cross_validation(path_to_save,\n",
    "                                       X,y, groups,\n",
    "                                       pipe,\n",
    "                                       param_grid, scoring,\n",
    "                                       compute_all_new, cv_out, cv_in,\n",
    "                                       search_function)\n",
    "#************************************************************************\n",
    "groups = data_groups.groups.keys()\n",
    "\n",
    "for learning_result, group in zip(learning_results, groups):\n",
    "        learning_result['group'] = group\n",
    "        \n",
    "cv_object = learning_results\n",
    "\n",
    "cv.generate_classification_report(cv_object)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "if hyper_param_heat:\n",
    "    for clf, test in learning_results:\n",
    "        print clf.best_estimator_\n",
    "        cv_results = clf.cv_results_\n",
    "        keys = cv_results.keys()\n",
    "\n",
    "        for grid in param_grid:\n",
    "            estimator_params = [key \n",
    "                                for key in grid.keys()\n",
    "                                if 'estimator' in key]\n",
    "            print estimator_params\n",
    "            param_bi_comb = itertools.combinations(estimator_params, r=2)\n",
    "\n",
    "            for bi_comb in param_bi_comb:\n",
    "\n",
    "                for key in keys:\n",
    "\n",
    "                    if 'param' not in key and 'rank' not in key:\n",
    "                        metric = cv_results[key]\n",
    "                        df = metric.reshape(len([2**i for i in xrange(-5, 11)]), len([2**i for i in xrange(-15, 1)]))\n",
    "\n",
    "                        #df = pd.DataFrame(df, columns=[str(2**i) for i in xrange(-15, 1)])\n",
    "                        #df['ix'] = [str(2**i) for i in xrange(-5, 11)]\n",
    "                        #df.set_index('ix')\n",
    "\n",
    "                        plt.figure()\n",
    "                        sns.heatmap(df,\n",
    "                                    xticklabels=[2**i for i in xrange(-5, 11)],\n",
    "                                    yticklabels=[2**i for i in xrange(-15, 1)],\n",
    "                                    cbar_kws={'label': key},\n",
    "                                   )\n",
    "                        plt.title(key)\n",
    "                        plt.xlabel(bi_comb[0])\n",
    "                        plt.ylabel(bi_comb[1])\n",
    "                        #plt.savefig(path_to_save + '/' + key)\n",
    "                        plt.show()\n",
    "                        \n",
    "hyper_param_list=False                        \n",
    "if hyper_param_list:\n",
    "    for learning_result in learning_results:\n",
    "\n",
    "        cv_results = learning_result['cv_results']\n",
    "        keys = list(cv_results.keys())\n",
    "        print keys\n",
    "        \n",
    "        for grid in param_grid:\n",
    "            params = grid.keys()\n",
    "            print params\n",
    "            for param in params:\n",
    "                \n",
    "                key_param_variation = keys[keys.index('param_' + param)]\n",
    "                param_variation = cv_results[key_param_variation]\n",
    "                \n",
    "                print param_variation\n",
    "                stop\n",
    "                \n",
    "                \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from classification.cross_validation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report = generate_classification_report(cv_object)\n",
    "report.to_hdf(path_to_save + 'classification_resport.h5', '/report' )\n",
    "\n",
    "pd.read_hdf(path_to_save + 'classification_resport.h5', '/report' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "string = report.to_latex()\n",
    "print string.replace('\\_', \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "arrays = [['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'],['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']]\n",
    "tuples = list(zip(*arrays))\n",
    "index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])\n",
    "s = pd.DataFrame(np.random.randn(8, 4), index=arrays)\n",
    "s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print s.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
